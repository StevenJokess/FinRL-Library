{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinRL_single_stock_trading.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Y9CM5DeIr9GC",
        "9upN8FI2r_X1",
        "CiBG2ZknsG73"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenJokess/FinRL-Library/blob/master/FinRL_single_stock_trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Idd1jem0TnST"
      },
      "source": [
        "# Deep Reinforcement Learning for Stock Trading from Scratch: Single Stock Trading\n",
        "\n",
        "Tutorials to use OpenAI DRL to trade single stock in one Jupyter Notebook | Presented at NeurIPS 2020: Deep RL Workshop\n",
        "\n",
        "* This blog is based on our paper: FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance, presented at NeurIPS 2020: Deep RL Workshop.\n",
        "* Check out medium blog for detailed explanations: https://towardsdatascience.com/finrl-for-quantitative-finance-tutorial-for-single-stock-trading-37d6d7c30aac\n",
        "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
        "* **Pytorch Version** \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vglc_9N5-KZ"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex2ord116AbP"
      },
      "source": [
        "* [1. Problem Definition](#0)\n",
        "* [2. Getting Started - Load Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. Check Additional Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5.Build Environment](#4)  \n",
        "    * [5.1. Training & Trade Data Split](#4.1)\n",
        "    * [5.2. User-defined Environment](#4.2)   \n",
        "    * [5.3. Initialize Environment](#4.3)    \n",
        "* [6.Implement DRL Algorithms](#5)  \n",
        "* [7.Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "    * [7.3. Baseline Stats](#6.3)   \n",
        "    * [7.3. Compare to Stock Market Index](#6.4)             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1eLhMW36cLi"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eimeRv06YoK"
      },
      "source": [
        "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
        "\n",
        "The components of the reinforcement learning environment are:\n",
        "\n",
        "\n",
        "* Action: The action space describes the allowed actions that the agent interacts with the\n",
        "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
        "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
        "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
        "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
        "\n",
        "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
        "values at state s′ and s, respectively\n",
        "\n",
        "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
        "our trading agent observes many different features to better learn in an interactive environment.\n",
        "\n",
        "* Environment: single stock trading for AAPL\n",
        "\n",
        "\n",
        "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n",
        "\n",
        "We use Apple Inc. stock: AAPL as an example throughout this article, because it is one of the most popular and profitable stocks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD3f90UnTnSU"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Getting Started- Load Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBUcBKap-oII"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40axJBAP5mer",
        "outputId": "24f5e8fb-682d-4172-c5b9-6dc494085274"
      },
      "source": [
        "## install finrl library\n",
        "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
            "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to /tmp/pip-req-build-u7sj9q15\n",
            "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-u7sj9q15\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from finrl==0.0.3) (1.19.5)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.6/dist-packages (from finrl==0.0.3) (1.1.5)\n",
            "Collecting stockstats\n",
            "  Downloading https://files.pythonhosted.org/packages/32/41/d3828c5bc0a262cb3112a4024108a3b019c183fa3b3078bff34bf25abf91/stockstats-0.3.2-py2.py3-none-any.whl\n",
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/e8/b9d7104d3a4bf39924799067592d9e59119fcfc900a425a12e80a3123ec8/yfinance-0.1.55.tar.gz\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from finrl==0.0.3) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from finrl==0.0.3) (0.22.2.post1)\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.6/dist-packages (from finrl==0.0.3) (0.17.3)\n",
            "Collecting stable-baselines3[extra]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/7c/ec89fd9a51c2ff640f150479069be817136c02f02349b5dd27a6e3bb8b3d/stable_baselines3-0.10.0-py3-none-any.whl (145kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from finrl==0.0.3) (3.6.4)\n",
            "Requirement already satisfied: setuptools>=41.4.0 in /usr/local/lib/python3.6/dist-packages (from finrl==0.0.3) (51.1.1)\n",
            "Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.6/dist-packages (from finrl==0.0.3) (0.36.2)\n",
            "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
            "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-pngwhxfz/pyfolio\n",
            "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-pngwhxfz/pyfolio\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.1.5->finrl==0.0.3) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.1.5->finrl==0.0.3) (2018.9)\n",
            "Collecting int-date>=0.1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/43/27/31803df15173ab341fe7548c14154b54227dfd8f630daa09a1c6e7db52f7/int_date-0.1.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from yfinance->finrl==0.0.3) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance->finrl==0.0.3) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/78/56a7c88a57d0d14945472535d0df9fb4bbad7d34ede658ec7961635c790e/lxml-4.6.2-cp36-cp36m-manylinux1_x86_64.whl (5.5MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5MB 29.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->finrl==0.0.3) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->finrl==0.0.3) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->finrl==0.0.3) (1.3.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->finrl==0.0.3) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->finrl==0.0.3) (1.0.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.17->finrl==0.0.3) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.17->finrl==0.0.3) (1.3.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]->finrl==0.0.3) (1.7.0+cu101)\n",
            "Requirement already satisfied: opencv-python; extra == \"extra\" in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]->finrl==0.0.3) (4.1.2.30)\n",
            "Requirement already satisfied: psutil; extra == \"extra\" in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]->finrl==0.0.3) (5.4.8)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"extra\" in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]->finrl==0.0.3) (0.2.6)\n",
            "Requirement already satisfied: tensorboard; extra == \"extra\" in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]->finrl==0.0.3) (2.4.0)\n",
            "Requirement already satisfied: pillow; extra == \"extra\" in /usr/local/lib/python3.6/dist-packages (from stable-baselines3[extra]->finrl==0.0.3) (7.0.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->finrl==0.0.3) (8.6.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->finrl==0.0.3) (20.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->finrl==0.0.3) (1.15.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->finrl==0.0.3) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->finrl==0.0.3) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->finrl==0.0.3) (1.10.0)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.6/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (5.5.0)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (0.11.1)\n",
            "Collecting empyrical>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/43/1b997c21411c6ab7c96dc034e160198272c7a785aeea7654c9bcf98bec83/empyrical-0.5.5.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance->finrl==0.0.3) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance->finrl==0.0.3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance->finrl==0.0.3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance->finrl==0.0.3) (1.24.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.0.3) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->stable-baselines3[extra]->finrl==0.0.3) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4.0->stable-baselines3[extra]->finrl==0.0.3) (3.7.4.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (0.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (1.17.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (3.12.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (1.7.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (1.32.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (4.3.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (0.8.1)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.6/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (0.9.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (3.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (4.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.0.3) (0.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard; extra == \"extra\"->stable-baselines3[extra]->finrl==0.0.3) (0.4.8)\n",
            "Building wheels for collected packages: finrl, yfinance, pyfolio, empyrical\n",
            "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for finrl: filename=finrl-0.0.3-cp36-none-any.whl size=20820 sha256=08631d020d321cd81167558e185431a7801a9e060509f834ac3c59f2315115ae\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cuw7fa_2/wheels/9c/19/bf/c644def96612df1ad42c94d5304966797eaa3221dffc5efe0b\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.55-py2.py3-none-any.whl size=22616 sha256=724cc7022ef4e3e20dc26a26aaf57f7422ddb70f66cac4c4152503ca6b31a625\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/98/cc/2702a4242d60bdc14f48b4557c427ded1fe92aedf257d4565c\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-cp36-none-any.whl size=75764 sha256=07c5c520ba80d40b9b1be7d2045d2d012bb62d841e993ce2df179e403e47fa8a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cuw7fa_2/wheels/43/ce/d9/6752fb6e03205408773235435205a0519d2c608a94f1976e56\n",
            "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empyrical: filename=empyrical-0.5.5-cp36-none-any.whl size=39765 sha256=247d2ed517bb091c60f692552887e82e98b400695915c585482be8bdff472d2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/b2/c8/6769d8444d2f2e608fae2641833110668d0ffd1abeb2e9f3fc\n",
            "Successfully built finrl yfinance pyfolio empyrical\n",
            "Installing collected packages: int-date, stockstats, lxml, yfinance, stable-baselines3, empyrical, pyfolio, finrl\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed empyrical-0.5.5 finrl-0.0.3 int-date-0.1.8 lxml-4.6.2 pyfolio-0.9.2+75.g4b901f6 stable-baselines3-0.10.0 stockstats-0.3.2 yfinance-0.1.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXyHD6ir5sxk"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. Check if the additional packages needed are present, if not install them. \n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG17M4JwTnSZ"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-0bsNMMTnSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "082d9448-5186-4012-9788-d6677c76e494"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "from finrl.config import config\n",
        "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
        "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
        "from finrl.preprocessing.data import data_split\n",
        "from finrl.env.env_stocktrading import StockTradingEnv\n",
        "from finrl.model.models import DRLAgent\n",
        "from finrl.trade.backtest import BackTestStats, BaselineStats, BackTestPlot\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
            "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIPbzYs1TnSd"
      },
      "source": [
        "#Diable the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pos2IZAL54pp"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. Create Folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp6lL6dZ53rX"
      },
      "source": [
        "import os\n",
        "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
        "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
        "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
        "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
        "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
        "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
        "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
        "    os.makedirs(\"./\" + config.RESULTS_DIR)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBPM0sVvTnSg"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCGVmtGzjORf"
      },
      "source": [
        "\n",
        "\n",
        "-----\n",
        "class YahooDownloader:\n",
        "    Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FBEiH5gOgMOx",
        "outputId": "83a5123f-f1e0-4a44-bbed-b26a97c747c6"
      },
      "source": [
        "# from config.py start_date is a string\n",
        "config.START_DATE"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2009-01-01'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sWLMNQ8CgMRx",
        "outputId": "328f2bda-bbac-4480-a5e2-597d15eb2c2d"
      },
      "source": [
        "# from config.py end_date is a string\n",
        "config.END_DATE"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2020-12-01'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmFpuBEZhkF3"
      },
      "source": [
        "ticker_list is a list of stock tickers, in a single stock trading case, the list contains only 1 ticker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtIFikNyTnSg",
        "outputId": "c189f03a-6e91-4af2-f407-734705454c2e"
      },
      "source": [
        "# Download and save the data in a pandas DataFrame:\n",
        "data_df = YahooDownloader(start_date = '2009-01-01',\n",
        "                          end_date = '2021-01-01',\n",
        "                          ticker_list = ['AAPL']).fetch_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (3021, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8ZKQmw6TnSl",
        "outputId": "5fb23031-1d24-4731-fae9-f4e9ee686905"
      },
      "source": [
        "data_df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3021, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Vi6D_ED6TnSs",
        "outputId": "c6938b01-8cb5-4df7-e3d9-1391ab06b5e4"
      },
      "source": [
        "data_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>3.067143</td>\n",
              "      <td>3.251429</td>\n",
              "      <td>3.041429</td>\n",
              "      <td>2.795913</td>\n",
              "      <td>746015200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-01-05</td>\n",
              "      <td>3.327500</td>\n",
              "      <td>3.435000</td>\n",
              "      <td>3.311071</td>\n",
              "      <td>2.913912</td>\n",
              "      <td>1181608400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-01-06</td>\n",
              "      <td>3.426786</td>\n",
              "      <td>3.470357</td>\n",
              "      <td>3.299643</td>\n",
              "      <td>2.865849</td>\n",
              "      <td>1289310400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-01-07</td>\n",
              "      <td>3.278929</td>\n",
              "      <td>3.303571</td>\n",
              "      <td>3.223572</td>\n",
              "      <td>2.803923</td>\n",
              "      <td>753048800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-01-08</td>\n",
              "      <td>3.229643</td>\n",
              "      <td>3.326786</td>\n",
              "      <td>3.215714</td>\n",
              "      <td>2.855991</td>\n",
              "      <td>673500800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date      open      high       low     close      volume   tic  day\n",
              "0  2009-01-02  3.067143  3.251429  3.041429  2.795913   746015200  AAPL    4\n",
              "1  2009-01-05  3.327500  3.435000  3.311071  2.913912  1181608400  AAPL    0\n",
              "2  2009-01-06  3.426786  3.470357  3.299643  2.865849  1289310400  AAPL    1\n",
              "3  2009-01-07  3.278929  3.303571  3.223572  2.803923   753048800  AAPL    2\n",
              "4  2009-01-08  3.229643  3.326786  3.215714  2.855991   673500800  AAPL    3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWiqgpLzTnS3"
      },
      "source": [
        "<a id='3'></a>\n",
        "# Part 4. Preprocess Data\n",
        "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
        "* FinRL uses a class **FeatureEngineer** to preprocess the data\n",
        "* Add **technical indicators**. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ9zmxpRks41"
      },
      "source": [
        "class FeatureEngineer:\n",
        "Provides methods for preprocessing the stock price data\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        df: DataFrame\n",
        "            data downloaded from Yahoo API\n",
        "        feature_number : int\n",
        "            number of features we used\n",
        "        use_technical_indicator : boolean\n",
        "            we technical indicator or not\n",
        "        use_turbulence : boolean\n",
        "            use turbulence index or not\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    preprocess_data()\n",
        "        main method to do the feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHu7i-T_wRPc"
      },
      "source": [
        "<a id='3.1'></a>\n",
        "\n",
        "## 4.1 Technical Indicators\n",
        "* FinRL uses stockstats to calcualte technical indicators such as **Moving Average Convergence Divergence (MACD)**, **Relative Strength Index (RSI)**, **Average Directional Index (ADX)**, **Commodity Channel Index (CCI)** and other various indicators and stats.\n",
        "* **stockstats**: supplies a wrapper StockDataFrame based on the **pandas.DataFrame** with inline stock statistics/indicators support.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RHwY1dHk09N",
        "outputId": "7a3716e7-0528-44af-d8a8-c3fffce0465d"
      },
      "source": [
        "## we store the stockstats technical indicator column names in config.py\n",
        "tech_indicator_list=config.TECHNICAL_INDICATORS_LIST\n",
        "print(tech_indicator_list)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['macd', 'rsi_30', 'cci_30', 'dx_30']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rImfGAfCkR8j",
        "outputId": "6bdcfb62-c37f-4fd2-cfd1-aa49d5552338"
      },
      "source": [
        "## user can add more technical indicators\n",
        "## check https://github.com/jealous/stockstats for different names\n",
        "tech_indicator_list=tech_indicator_list+['kdjk','open_2_sma','boll','close_10.0_le_5_c','wr_10','dma','trix']\n",
        "print(tech_indicator_list)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['macd', 'rsi_30', 'cci_30', 'dx_30', 'kdjk', 'open_2_sma', 'boll', 'close_10.0_le_5_c', 'wr_10', 'dma', 'trix']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etvRo2rSwZPg"
      },
      "source": [
        "<a id='3.2'></a>\n",
        "## 4.2 Perform Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAOsx0m-9u2k",
        "outputId": "af24dfd1-191e-4c00-f2d3-bed422ed7c23"
      },
      "source": [
        "fe = FeatureEngineer(\n",
        "                    use_technical_indicator=True,\n",
        "                    tech_indicator_list = tech_indicator_list,\n",
        "                    use_turbulence=False,\n",
        "                    user_defined_feature = False)\n",
        "\n",
        "data_df = fe.preprocess_data(data_df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully added technical indicators\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "wytX_qwWMHP5",
        "outputId": "6f4f9b2c-a6cd-47ed-9091-47ca52da4d10"
      },
      "source": [
        "data_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>kdjk</th>\n",
              "      <th>open_2_sma</th>\n",
              "      <th>boll</th>\n",
              "      <th>close_10.0_le_5_c</th>\n",
              "      <th>wr_10</th>\n",
              "      <th>dma</th>\n",
              "      <th>trix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>3.067143</td>\n",
              "      <td>3.251429</td>\n",
              "      <td>3.041429</td>\n",
              "      <td>2.795913</td>\n",
              "      <td>746015200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>-5.637387</td>\n",
              "      <td>3.067143</td>\n",
              "      <td>2.795913</td>\n",
              "      <td>1.0</td>\n",
              "      <td>216.912162</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.670734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-01-05</td>\n",
              "      <td>3.327500</td>\n",
              "      <td>3.435000</td>\n",
              "      <td>3.311071</td>\n",
              "      <td>2.913912</td>\n",
              "      <td>1181608400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002647</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>-14.558226</td>\n",
              "      <td>3.197322</td>\n",
              "      <td>2.854912</td>\n",
              "      <td>2.0</td>\n",
              "      <td>132.399904</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.670734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-01-06</td>\n",
              "      <td>3.426786</td>\n",
              "      <td>3.470357</td>\n",
              "      <td>3.299643</td>\n",
              "      <td>2.865849</td>\n",
              "      <td>1289310400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1</td>\n",
              "      <td>0.001883</td>\n",
              "      <td>70.355297</td>\n",
              "      <td>46.762875</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>-23.350262</td>\n",
              "      <td>3.377143</td>\n",
              "      <td>2.858558</td>\n",
              "      <td>3.0</td>\n",
              "      <td>140.934334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.391303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-01-07</td>\n",
              "      <td>3.278929</td>\n",
              "      <td>3.303571</td>\n",
              "      <td>3.223572</td>\n",
              "      <td>2.803923</td>\n",
              "      <td>753048800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.000747</td>\n",
              "      <td>50.429222</td>\n",
              "      <td>-29.787322</td>\n",
              "      <td>43.608349</td>\n",
              "      <td>-34.024085</td>\n",
              "      <td>3.352857</td>\n",
              "      <td>2.844899</td>\n",
              "      <td>4.0</td>\n",
              "      <td>155.371731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.195391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-01-08</td>\n",
              "      <td>3.229643</td>\n",
              "      <td>3.326786</td>\n",
              "      <td>3.215714</td>\n",
              "      <td>2.855991</td>\n",
              "      <td>673500800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.000088</td>\n",
              "      <td>60.227071</td>\n",
              "      <td>-9.011779</td>\n",
              "      <td>48.358256</td>\n",
              "      <td>-37.093625</td>\n",
              "      <td>3.254286</td>\n",
              "      <td>2.847118</td>\n",
              "      <td>5.0</td>\n",
              "      <td>143.232705</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125124</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date      open      high  ...       wr_10  dma      trix\n",
              "0  2009-01-02  3.067143  3.251429  ...  216.912162  0.0  0.670734\n",
              "1  2009-01-05  3.327500  3.435000  ...  132.399904  0.0  0.670734\n",
              "2  2009-01-06  3.426786  3.470357  ...  140.934334  0.0  0.391303\n",
              "3  2009-01-07  3.278929  3.303571  ...  155.371731  0.0  0.195391\n",
              "4  2009-01-08  3.229643  3.326786  ...  143.232705  0.0  0.125124\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwLhXo1cTnTQ"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Build Environment\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
        "\n",
        "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D1FlBdOL4b3"
      },
      "source": [
        "<a id='4.1'></a>\n",
        "## 5.1 Training & Trade data split\n",
        "* Training: 2009-01-01 to 2018-12-31\n",
        "* Trade: 2019-01-01 to 2020-09-30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNOdqfTKL6K-"
      },
      "source": [
        "#train = data_split(data_df, start = config.START_DATE, end = config.START_TRADE_DATE)\n",
        "#trade = data_split(data_df, start = config.START_TRADE_DATE, end = config.END_DATE)\n",
        "train = data_split(data_df, start = '2009-01-01', end = '2019-01-01')\n",
        "trade = data_split(data_df, start = '2019-01-01', end = '2021-01-01')\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUxOshVouLXt"
      },
      "source": [
        "## data normalization, this part is optional, have little impact\n",
        "#feaures_list = list(train.columns)\n",
        "#feaures_list.remove('date')\n",
        "#feaures_list.remove('tic')\n",
        "#feaures_list.remove('close')\n",
        "#print(feaures_list)\n",
        "#from sklearn import preprocessing\n",
        "#data_normaliser = preprocessing.StandardScaler()\n",
        "#train[feaures_list] = data_normaliser.fit_transform(train[feaures_list])\n",
        "#trade[feaures_list] = data_normaliser.transform(trade[feaures_list])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMHyaSBBDGbe"
      },
      "source": [
        "<a id='4.2'></a>\n",
        "## 5.2 User-defined Environment: a simulation environment class "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90V3S7cpDcQs"
      },
      "source": [
        "<a id='4.3'></a>\n",
        "## 5.3 Initialize Environment\n",
        "* **stock dimension**: the number of unique stock tickers we use\n",
        "* **hmax**: the maximum amount of shares to buy or sell\n",
        "* **initial amount**: the amount of money we use to trade in the begining\n",
        "* **transaction cost percentage**: a per share rate for every share trade\n",
        "* **tech_indicator_list**: a list of technical indicator names (modified from config.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiH0xO96mGcL",
        "outputId": "b16d8b9e-7c41-41b5-c8d0-5b7f83d1426e"
      },
      "source": [
        "## we store the stockstats technical indicator column names in config.py\n",
        "## check https://github.com/jealous/stockstats for different names\n",
        "tech_indicator_list"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['macd',\n",
              " 'rsi_30',\n",
              " 'cci_30',\n",
              " 'dx_30',\n",
              " 'kdjk',\n",
              " 'open_2_sma',\n",
              " 'boll',\n",
              " 'close_10.0_le_5_c',\n",
              " 'wr_10',\n",
              " 'dma',\n",
              " 'trix']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnWOKS7DyGM7",
        "outputId": "93992220-cb7c-4536-d31b-47844443bc1d"
      },
      "source": [
        "# the stock dimension is 1, because we only use the price data of AAPL.\n",
        "len(train.tic.unique())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipJcnLvQGAba",
        "outputId": "1ff38d5d-8815-493b-fade-2f57dce7b7bc"
      },
      "source": [
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stock Dimension: 1, State Space: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY5wTwYjGTrg"
      },
      "source": [
        "env_kwargs = {\r\n",
        "    \"hmax\": 100, \r\n",
        "    \"initial_amount\": 100000, \r\n",
        "    \"transaction_cost_pct\": 0.001, \r\n",
        "    \"state_space\": state_space, \r\n",
        "    \"stock_dim\": stock_dimension, \r\n",
        "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \r\n",
        "    \"action_space\": stock_dimension, \r\n",
        "    \"reward_scaling\": 1e-4\r\n",
        "    \r\n",
        "}\r\n",
        "\r\n",
        "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\r\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmyi2IPnyEkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd40a128-8d89-43c1-8da7-941385566430"
      },
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdnzYtM1TnTW"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Implement DRL Algorithms\n",
        "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
        "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
        "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
        "design their own DRL algorithms by adapting these DRL algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRFIZDw8TnTX"
      },
      "source": [
        "agent = DRLAgent(env = env_train)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD1NHzGyTnTc"
      },
      "source": [
        "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9CM5DeIr9GC"
      },
      "source": [
        "### Model 1: A2C"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOk-Mr73-EEq",
        "outputId": "0b9c551c-dc7e-4370-9c2f-5fc91d128a0c"
      },
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
        "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXHEidJh-E60",
        "outputId": "51efe46b-ed22-44dd-961d-0d3a6135b896"
      },
      "source": [
        "trained_a2c = agent.train_model(model=model_a2c, \n",
        "                                tb_log_name='a2c',\n",
        "                                total_timesteps=50000)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to tensorboard_log/a2c/a2c_1\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 72       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.43    |\n",
            "|    explained_variance | 0.342    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 0.00782  |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 0.00017  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 116      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.43    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -0.0915  |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.00507  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 149      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.44    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -0.0237  |\n",
            "|    std                | 1.02     |\n",
            "|    value_loss         | 0.000611 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 173       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.45     |\n",
            "|    explained_variance | -1.74e+12 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -0.0096   |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 4.42e-05  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 192      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.45    |\n",
            "|    explained_variance | -20.2    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 0.165    |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.0218   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 1.06e+05 |\n",
            "|    total_cost         | 3.08e+03 |\n",
            "|    total_reward       | 5.9e+03  |\n",
            "|    total_reward_pct   | 5.9      |\n",
            "|    total_trades       | 2447     |\n",
            "| time/                 |          |\n",
            "|    fps                | 206      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 0.000984 |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 5.02e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 217      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 0.22     |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.0399   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 227      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | -0.371   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 0.209    |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.0863   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 235      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | -7.69    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | -0.367   |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 0.134    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 240      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.46    |\n",
            "|    explained_variance | -71.9    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | -1.97    |\n",
            "|    std                | 1.04     |\n",
            "|    value_loss         | 2.87     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 2.1e+05  |\n",
            "|    total_cost         | 3.37e+03 |\n",
            "|    total_reward       | 1.1e+05  |\n",
            "|    total_reward_pct   | 110      |\n",
            "|    total_trades       | 2495     |\n",
            "| time/                 |          |\n",
            "|    fps                | 247      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 22       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.47    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 0.0563   |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 0.00362  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 252      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 23       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.47    |\n",
            "|    explained_variance | -36.4    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | -0.554   |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 0.188    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 257      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 25       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.47    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.558    |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 0.403    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 260      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.47    |\n",
            "|    explained_variance | -0.0959  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | -0.226   |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 0.0274   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 263      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.47    |\n",
            "|    explained_variance | -16.3    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | -0.897   |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 1.4      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 2.63e+05 |\n",
            "|    total_cost         | 3.48e+03 |\n",
            "|    total_reward       | 1.63e+05 |\n",
            "|    total_reward_pct   | 163      |\n",
            "|    total_trades       | 2491     |\n",
            "| time/                 |          |\n",
            "|    fps                | 266      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 29       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.47    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.16     |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 0.0101   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 269      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 31       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.47    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | -0.138   |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 0.055    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 271      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 33       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.47    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 0.00314  |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 0.0439   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 273      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.47    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -0.207   |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.0389   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 275      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 36       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.47    |\n",
            "|    explained_variance | -9.9     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | -0.593   |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.242    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 3.58e+05 |\n",
            "|    total_cost         | 3.48e+03 |\n",
            "|    total_reward       | 2.58e+05 |\n",
            "|    total_reward_pct   | 258      |\n",
            "|    total_trades       | 2515     |\n",
            "| time/                 |          |\n",
            "|    fps                | 277      |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 37       |\n",
            "|    total_timesteps    | 10500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | 0.017    |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.000224 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 278      |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 39       |\n",
            "|    total_timesteps    | 11000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | -0.0374  |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.0035   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 280      |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 41       |\n",
            "|    total_timesteps    | 11500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | 0.0349   |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | 0.839    |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.109    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 280      |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 42       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | -0.0466  |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | 0.107    |\n",
            "|    std                | 1.06     |\n",
            "|    value_loss         | 0.0135   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 281      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 44       |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | -8.48    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | 1.12     |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.78     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 2.4e+05  |\n",
            "|    total_cost         | 3.37e+03 |\n",
            "|    total_reward       | 1.4e+05  |\n",
            "|    total_reward_pct   | 140      |\n",
            "|    total_trades       | 2470     |\n",
            "| time/                 |          |\n",
            "|    fps                | 282      |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 46       |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | -0.0495  |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.00224  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 283      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 47       |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 0.897    |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.157    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 283      |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 49       |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | 0.215    |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.0323   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 284      |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 50       |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | 0.0218   |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.0132   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 285       |\n",
            "|    iterations         | 3000      |\n",
            "|    time_elapsed       | 52        |\n",
            "|    total_timesteps    | 15000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.49     |\n",
            "|    explained_variance | -5.17e+03 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 2999      |\n",
            "|    policy_loss        | 0.821     |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 1.16      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 2.44e+05 |\n",
            "|    total_cost         | 3.53e+03 |\n",
            "|    total_reward       | 1.44e+05 |\n",
            "|    total_reward_pct   | 144      |\n",
            "|    total_trades       | 2514     |\n",
            "| time/                 |          |\n",
            "|    fps                | 286      |\n",
            "|    iterations         | 3100     |\n",
            "|    time_elapsed       | 54       |\n",
            "|    total_timesteps    | 15500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3099     |\n",
            "|    policy_loss        | 0.0299   |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.000779 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 287      |\n",
            "|    iterations         | 3200     |\n",
            "|    time_elapsed       | 55       |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3199     |\n",
            "|    policy_loss        | -0.467   |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.155    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 288      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 57       |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | -36.9    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | 0.46     |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.209    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 289      |\n",
            "|    iterations         | 3400     |\n",
            "|    time_elapsed       | 58       |\n",
            "|    total_timesteps    | 17000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3399     |\n",
            "|    policy_loss        | 0.35     |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 0.0952   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 290      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 60       |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | -31.3    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | 0.219    |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.0679   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 3.27e+05 |\n",
            "|    total_cost         | 3.55e+03 |\n",
            "|    total_reward       | 2.27e+05 |\n",
            "|    total_reward_pct   | 227      |\n",
            "|    total_trades       | 2511     |\n",
            "| time/                 |          |\n",
            "|    fps                | 291      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 61       |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | -0.177   |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.0437   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 292      |\n",
            "|    iterations         | 3700     |\n",
            "|    time_elapsed       | 63       |\n",
            "|    total_timesteps    | 18500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | -124     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3699     |\n",
            "|    policy_loss        | 1.71     |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 1.02     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 293      |\n",
            "|    iterations         | 3800     |\n",
            "|    time_elapsed       | 64       |\n",
            "|    total_timesteps    | 19000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | -204     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3799     |\n",
            "|    policy_loss        | 0.485    |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.244    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 293      |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 66       |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | -12.5    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | -1.56    |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.999    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 294      |\n",
            "|    iterations         | 4000     |\n",
            "|    time_elapsed       | 68       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | -12.2    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 3999     |\n",
            "|    policy_loss        | -1.29    |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 1.06     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| environment/          |           |\n",
            "|    portfolio_value    | 5.1e+05   |\n",
            "|    total_cost         | 3.5e+03   |\n",
            "|    total_reward       | 4.1e+05   |\n",
            "|    total_reward_pct   | 410       |\n",
            "|    total_trades       | 2513      |\n",
            "| time/                 |           |\n",
            "|    fps                | 294       |\n",
            "|    iterations         | 4100      |\n",
            "|    time_elapsed       | 69        |\n",
            "|    total_timesteps    | 20500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.49     |\n",
            "|    explained_variance | -1.44e+03 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4099      |\n",
            "|    policy_loss        | 0.676     |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 0.269     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 295      |\n",
            "|    iterations         | 4200     |\n",
            "|    time_elapsed       | 71       |\n",
            "|    total_timesteps    | 21000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.49    |\n",
            "|    explained_variance | -4.79    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4199     |\n",
            "|    policy_loss        | 0.503    |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.25     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 295      |\n",
            "|    iterations         | 4300     |\n",
            "|    time_elapsed       | 72       |\n",
            "|    total_timesteps    | 21500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.5     |\n",
            "|    explained_variance | -6.46    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4299     |\n",
            "|    policy_loss        | 1.5      |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.35     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 295      |\n",
            "|    iterations         | 4400     |\n",
            "|    time_elapsed       | 74       |\n",
            "|    total_timesteps    | 22000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.5     |\n",
            "|    explained_variance | -137     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4399     |\n",
            "|    policy_loss        | -0.759   |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.541    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 296      |\n",
            "|    iterations         | 4500     |\n",
            "|    time_elapsed       | 75       |\n",
            "|    total_timesteps    | 22500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.5     |\n",
            "|    explained_variance | -48.8    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4499     |\n",
            "|    policy_loss        | -0.427   |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.0845   |\n",
            "------------------------------------\n",
            "day: 2515, episode: 10\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 592125.91\n",
            "total_reward: 492125.91\n",
            "total_cost: 3404.97\n",
            "total_trades: 2515\n",
            "Sharpe: 0.888\n",
            "=================================\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 5.92e+05 |\n",
            "|    total_cost         | 3.4e+03  |\n",
            "|    total_reward       | 4.92e+05 |\n",
            "|    total_reward_pct   | 492      |\n",
            "|    total_trades       | 2515     |\n",
            "| time/                 |          |\n",
            "|    fps                | 296      |\n",
            "|    iterations         | 4600     |\n",
            "|    time_elapsed       | 77       |\n",
            "|    total_timesteps    | 23000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.5     |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4599     |\n",
            "|    policy_loss        | -0.0695  |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.0397   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 296      |\n",
            "|    iterations         | 4700     |\n",
            "|    time_elapsed       | 79       |\n",
            "|    total_timesteps    | 23500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.5     |\n",
            "|    explained_variance | -186     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4699     |\n",
            "|    policy_loss        | -1.58    |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 2.12     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 297      |\n",
            "|    iterations         | 4800     |\n",
            "|    time_elapsed       | 80       |\n",
            "|    total_timesteps    | 24000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.5     |\n",
            "|    explained_variance | -17.3    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4799     |\n",
            "|    policy_loss        | 0.368    |\n",
            "|    std                | 1.08     |\n",
            "|    value_loss         | 0.103    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 298      |\n",
            "|    iterations         | 4900     |\n",
            "|    time_elapsed       | 82       |\n",
            "|    total_timesteps    | 24500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.5     |\n",
            "|    explained_variance | -6.12    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 4899     |\n",
            "|    policy_loss        | -0.813   |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.158    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 298       |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 83        |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.5      |\n",
            "|    explained_variance | -1.91e+03 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | 6.55      |\n",
            "|    std                | 1.09      |\n",
            "|    value_loss         | 26.6      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 6.75e+05 |\n",
            "|    total_cost         | 3.46e+03 |\n",
            "|    total_reward       | 5.75e+05 |\n",
            "|    total_reward_pct   | 575      |\n",
            "|    total_trades       | 2515     |\n",
            "| time/                 |          |\n",
            "|    fps                | 299      |\n",
            "|    iterations         | 5100     |\n",
            "|    time_elapsed       | 85       |\n",
            "|    total_timesteps    | 25500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5099     |\n",
            "|    policy_loss        | -0.489   |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.146    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 299      |\n",
            "|    iterations         | 5200     |\n",
            "|    time_elapsed       | 86       |\n",
            "|    total_timesteps    | 26000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -44.1    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5199     |\n",
            "|    policy_loss        | 2.29     |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 2.4      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 300      |\n",
            "|    iterations         | 5300     |\n",
            "|    time_elapsed       | 88       |\n",
            "|    total_timesteps    | 26500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -14.5    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5299     |\n",
            "|    policy_loss        | 3.05     |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 5.4      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 300      |\n",
            "|    iterations         | 5400     |\n",
            "|    time_elapsed       | 89       |\n",
            "|    total_timesteps    | 27000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -187     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5399     |\n",
            "|    policy_loss        | -3.02    |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 2.9      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 301      |\n",
            "|    iterations         | 5500     |\n",
            "|    time_elapsed       | 91       |\n",
            "|    total_timesteps    | 27500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -216     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5499     |\n",
            "|    policy_loss        | 1.35     |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 2.22     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 6.96e+05 |\n",
            "|    total_cost         | 3.26e+03 |\n",
            "|    total_reward       | 5.96e+05 |\n",
            "|    total_reward_pct   | 596      |\n",
            "|    total_trades       | 2514     |\n",
            "| time/                 |          |\n",
            "|    fps                | 301      |\n",
            "|    iterations         | 5600     |\n",
            "|    time_elapsed       | 92       |\n",
            "|    total_timesteps    | 28000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5599     |\n",
            "|    policy_loss        | 0.025    |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.00141  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 301      |\n",
            "|    iterations         | 5700     |\n",
            "|    time_elapsed       | 94       |\n",
            "|    total_timesteps    | 28500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -67.4    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5699     |\n",
            "|    policy_loss        | 1.06     |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.892    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 302      |\n",
            "|    iterations         | 5800     |\n",
            "|    time_elapsed       | 95       |\n",
            "|    total_timesteps    | 29000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -59.2    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5799     |\n",
            "|    policy_loss        | 0.0493   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.0717   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 302      |\n",
            "|    iterations         | 5900     |\n",
            "|    time_elapsed       | 97       |\n",
            "|    total_timesteps    | 29500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -119     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5899     |\n",
            "|    policy_loss        | -0.846   |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.265    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 303      |\n",
            "|    iterations         | 6000     |\n",
            "|    time_elapsed       | 98       |\n",
            "|    total_timesteps    | 30000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -774     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 5999     |\n",
            "|    policy_loss        | -4.46    |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 8.38     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 7.47e+05 |\n",
            "|    total_cost         | 3.4e+03  |\n",
            "|    total_reward       | 6.47e+05 |\n",
            "|    total_reward_pct   | 647      |\n",
            "|    total_trades       | 2514     |\n",
            "| time/                 |          |\n",
            "|    fps                | 303      |\n",
            "|    iterations         | 6100     |\n",
            "|    time_elapsed       | 100      |\n",
            "|    total_timesteps    | 30500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6099     |\n",
            "|    policy_loss        | -0.141   |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.0271   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 304       |\n",
            "|    iterations         | 6200      |\n",
            "|    time_elapsed       | 101       |\n",
            "|    total_timesteps    | 31000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.51     |\n",
            "|    explained_variance | -1.21e+04 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6199      |\n",
            "|    policy_loss        | 1.1       |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.733     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 304      |\n",
            "|    iterations         | 6300     |\n",
            "|    time_elapsed       | 103      |\n",
            "|    total_timesteps    | 31500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -25.3    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6299     |\n",
            "|    policy_loss        | -0.151   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.0159   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 304      |\n",
            "|    iterations         | 6400     |\n",
            "|    time_elapsed       | 104      |\n",
            "|    total_timesteps    | 32000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -640     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6399     |\n",
            "|    policy_loss        | 2.6      |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 2.28     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 305       |\n",
            "|    iterations         | 6500      |\n",
            "|    time_elapsed       | 106       |\n",
            "|    total_timesteps    | 32500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.51     |\n",
            "|    explained_variance | -1.02e+03 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 6499      |\n",
            "|    policy_loss        | 1.97      |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 5.17      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 7.46e+05 |\n",
            "|    total_cost         | 3.28e+03 |\n",
            "|    total_reward       | 6.46e+05 |\n",
            "|    total_reward_pct   | 646      |\n",
            "|    total_trades       | 2515     |\n",
            "| time/                 |          |\n",
            "|    fps                | 305      |\n",
            "|    iterations         | 6600     |\n",
            "|    time_elapsed       | 108      |\n",
            "|    total_timesteps    | 33000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6599     |\n",
            "|    policy_loss        | -0.297   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.0444   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 305      |\n",
            "|    iterations         | 6700     |\n",
            "|    time_elapsed       | 109      |\n",
            "|    total_timesteps    | 33500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6699     |\n",
            "|    policy_loss        | 0.224    |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.122    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 306      |\n",
            "|    iterations         | 6800     |\n",
            "|    time_elapsed       | 111      |\n",
            "|    total_timesteps    | 34000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.5     |\n",
            "|    explained_variance | -73.2    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6799     |\n",
            "|    policy_loss        | 1.48     |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 1.55     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 306      |\n",
            "|    iterations         | 6900     |\n",
            "|    time_elapsed       | 112      |\n",
            "|    total_timesteps    | 34500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -97.4    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6899     |\n",
            "|    policy_loss        | -0.125   |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.225    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 306      |\n",
            "|    iterations         | 7000     |\n",
            "|    time_elapsed       | 114      |\n",
            "|    total_timesteps    | 35000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -35      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 6999     |\n",
            "|    policy_loss        | -5.49    |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 15.5     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 7.49e+05 |\n",
            "|    total_cost         | 3.54e+03 |\n",
            "|    total_reward       | 6.49e+05 |\n",
            "|    total_reward_pct   | 649      |\n",
            "|    total_trades       | 2515     |\n",
            "| time/                 |          |\n",
            "|    fps                | 306      |\n",
            "|    iterations         | 7100     |\n",
            "|    time_elapsed       | 115      |\n",
            "|    total_timesteps    | 35500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -25.7    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7099     |\n",
            "|    policy_loss        | -0.792   |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.328    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 305      |\n",
            "|    iterations         | 7200     |\n",
            "|    time_elapsed       | 117      |\n",
            "|    total_timesteps    | 36000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7199     |\n",
            "|    policy_loss        | 1.69     |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 1.16     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 306      |\n",
            "|    iterations         | 7300     |\n",
            "|    time_elapsed       | 119      |\n",
            "|    total_timesteps    | 36500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -336     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7299     |\n",
            "|    policy_loss        | -0.0332  |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.132    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 306      |\n",
            "|    iterations         | 7400     |\n",
            "|    time_elapsed       | 120      |\n",
            "|    total_timesteps    | 37000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -392     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7399     |\n",
            "|    policy_loss        | -1.39    |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.65     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 306      |\n",
            "|    iterations         | 7500     |\n",
            "|    time_elapsed       | 122      |\n",
            "|    total_timesteps    | 37500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -13.4    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7499     |\n",
            "|    policy_loss        | 0.564    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.273    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 6.93e+05 |\n",
            "|    total_cost         | 3.59e+03 |\n",
            "|    total_reward       | 5.93e+05 |\n",
            "|    total_reward_pct   | 593      |\n",
            "|    total_trades       | 2515     |\n",
            "| time/                 |          |\n",
            "|    fps                | 306      |\n",
            "|    iterations         | 7600     |\n",
            "|    time_elapsed       | 124      |\n",
            "|    total_timesteps    | 38000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7599     |\n",
            "|    policy_loss        | -0.266   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.0288   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 306      |\n",
            "|    iterations         | 7700     |\n",
            "|    time_elapsed       | 125      |\n",
            "|    total_timesteps    | 38500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7699     |\n",
            "|    policy_loss        | -0.109   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.0153   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 306       |\n",
            "|    iterations         | 7800      |\n",
            "|    time_elapsed       | 127       |\n",
            "|    total_timesteps    | 39000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.51     |\n",
            "|    explained_variance | -1.46e+03 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 7799      |\n",
            "|    policy_loss        | 0.0117    |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.288     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 306      |\n",
            "|    iterations         | 7900     |\n",
            "|    time_elapsed       | 128      |\n",
            "|    total_timesteps    | 39500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -294     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7899     |\n",
            "|    policy_loss        | -0.698   |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 1.29     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 306      |\n",
            "|    iterations         | 8000     |\n",
            "|    time_elapsed       | 130      |\n",
            "|    total_timesteps    | 40000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -220     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 7999     |\n",
            "|    policy_loss        | 1.26     |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.912    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 6.88e+05 |\n",
            "|    total_cost         | 3.58e+03 |\n",
            "|    total_reward       | 5.88e+05 |\n",
            "|    total_reward_pct   | 588      |\n",
            "|    total_trades       | 2515     |\n",
            "| time/                 |          |\n",
            "|    fps                | 307      |\n",
            "|    iterations         | 8100     |\n",
            "|    time_elapsed       | 131      |\n",
            "|    total_timesteps    | 40500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8099     |\n",
            "|    policy_loss        | 0.0911   |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.0203   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 307      |\n",
            "|    iterations         | 8200     |\n",
            "|    time_elapsed       | 133      |\n",
            "|    total_timesteps    | 41000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -2.9     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8199     |\n",
            "|    policy_loss        | -0.183   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.0372   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 307       |\n",
            "|    iterations         | 8300      |\n",
            "|    time_elapsed       | 135       |\n",
            "|    total_timesteps    | 41500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.51     |\n",
            "|    explained_variance | -5.33e+12 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8299      |\n",
            "|    policy_loss        | 0.94      |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.769     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 307      |\n",
            "|    iterations         | 8400     |\n",
            "|    time_elapsed       | 136      |\n",
            "|    total_timesteps    | 42000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8399     |\n",
            "|    policy_loss        | -0.0137  |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.0856   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 307      |\n",
            "|    iterations         | 8500     |\n",
            "|    time_elapsed       | 138      |\n",
            "|    total_timesteps    | 42500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -26.3    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8499     |\n",
            "|    policy_loss        | 3        |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 3.16     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 6.77e+05 |\n",
            "|    total_cost         | 3.57e+03 |\n",
            "|    total_reward       | 5.77e+05 |\n",
            "|    total_reward_pct   | 577      |\n",
            "|    total_trades       | 2515     |\n",
            "| time/                 |          |\n",
            "|    fps                | 307      |\n",
            "|    iterations         | 8600     |\n",
            "|    time_elapsed       | 139      |\n",
            "|    total_timesteps    | 43000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8599     |\n",
            "|    policy_loss        | -0.342   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.0726   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 308      |\n",
            "|    iterations         | 8700     |\n",
            "|    time_elapsed       | 141      |\n",
            "|    total_timesteps    | 43500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -104     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8699     |\n",
            "|    policy_loss        | -1.76    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 1.06     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 308      |\n",
            "|    iterations         | 8800     |\n",
            "|    time_elapsed       | 142      |\n",
            "|    total_timesteps    | 44000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -61.8    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8799     |\n",
            "|    policy_loss        | 0.024    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.0689   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 308      |\n",
            "|    iterations         | 8900     |\n",
            "|    time_elapsed       | 144      |\n",
            "|    total_timesteps    | 44500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -5.94    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 8899     |\n",
            "|    policy_loss        | 0.135    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.139    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 308       |\n",
            "|    iterations         | 9000      |\n",
            "|    time_elapsed       | 145       |\n",
            "|    total_timesteps    | 45000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.51     |\n",
            "|    explained_variance | -1.78e+08 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 8999      |\n",
            "|    policy_loss        | 4.96      |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 18.7      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 7.42e+05 |\n",
            "|    total_cost         | 3.12e+03 |\n",
            "|    total_reward       | 6.42e+05 |\n",
            "|    total_reward_pct   | 642      |\n",
            "|    total_trades       | 2514     |\n",
            "| time/                 |          |\n",
            "|    fps                | 308      |\n",
            "|    iterations         | 9100     |\n",
            "|    time_elapsed       | 147      |\n",
            "|    total_timesteps    | 45500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9099     |\n",
            "|    policy_loss        | -0.525   |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.242    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 308      |\n",
            "|    iterations         | 9200     |\n",
            "|    time_elapsed       | 149      |\n",
            "|    total_timesteps    | 46000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -705     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9199     |\n",
            "|    policy_loss        | -2.04    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 2.18     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 308      |\n",
            "|    iterations         | 9300     |\n",
            "|    time_elapsed       | 150      |\n",
            "|    total_timesteps    | 46500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -572     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9299     |\n",
            "|    policy_loss        | 0.765    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.334    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 308       |\n",
            "|    iterations         | 9400      |\n",
            "|    time_elapsed       | 152       |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.51     |\n",
            "|    explained_variance | -4.93e+03 |\n",
            "|    learning_rate      | 0.0002    |\n",
            "|    n_updates          | 9399      |\n",
            "|    policy_loss        | -0.894    |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.554     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 309      |\n",
            "|    iterations         | 9500     |\n",
            "|    time_elapsed       | 153      |\n",
            "|    total_timesteps    | 47500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | -12.8    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9499     |\n",
            "|    policy_loss        | 0.927    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.464    |\n",
            "------------------------------------\n",
            "day: 2515, episode: 20\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 758593.13\n",
            "total_reward: 658593.13\n",
            "total_cost: 3213.99\n",
            "total_trades: 2514\n",
            "Sharpe: 0.959\n",
            "=================================\n",
            "------------------------------------\n",
            "| environment/          |          |\n",
            "|    portfolio_value    | 7.59e+05 |\n",
            "|    total_cost         | 3.21e+03 |\n",
            "|    total_reward       | 6.59e+05 |\n",
            "|    total_reward_pct   | 659      |\n",
            "|    total_trades       | 2514     |\n",
            "| time/                 |          |\n",
            "|    fps                | 309      |\n",
            "|    iterations         | 9600     |\n",
            "|    time_elapsed       | 155      |\n",
            "|    total_timesteps    | 48000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.51    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9599     |\n",
            "|    policy_loss        | 0.239    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.037    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 308      |\n",
            "|    iterations         | 9700     |\n",
            "|    time_elapsed       | 157      |\n",
            "|    total_timesteps    | 48500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | -185     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9699     |\n",
            "|    policy_loss        | -1.13    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.713    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 308      |\n",
            "|    iterations         | 9800     |\n",
            "|    time_elapsed       | 158      |\n",
            "|    total_timesteps    | 49000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | -234     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9799     |\n",
            "|    policy_loss        | 0.572    |\n",
            "|    std                | 1.1      |\n",
            "|    value_loss         | 0.411    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 308      |\n",
            "|    iterations         | 9900     |\n",
            "|    time_elapsed       | 160      |\n",
            "|    total_timesteps    | 49500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | -622     |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9899     |\n",
            "|    policy_loss        | -0.934   |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 0.969    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 308      |\n",
            "|    iterations         | 10000    |\n",
            "|    time_elapsed       | 161      |\n",
            "|    total_timesteps    | 50000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.52    |\n",
            "|    explained_variance | -63.2    |\n",
            "|    learning_rate      | 0.0002   |\n",
            "|    n_updates          | 9999     |\n",
            "|    policy_loss        | 0.0392   |\n",
            "|    std                | 1.11     |\n",
            "|    value_loss         | 0.343    |\n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9upN8FI2r_X1"
      },
      "source": [
        "### Model 2: DDPG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUFJlHsi-Ka-",
        "outputId": "7c20ba3f-671a-40d2-f625-0f30bdf426c9"
      },
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "DDPG_PARAMS = {\"batch_size\": 64, \"buffer_size\": 500000, \"learning_rate\": 0.0001}\n",
        "\n",
        "\n",
        "model_ddpg = agent.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 64, 'buffer_size': 500000, 'learning_rate': 0.0001}\n",
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5J_Scwp-Nis",
        "outputId": "cf0689f5-848e-4277-cc56-fa792db9166c"
      },
      "source": [
        "trained_ddpg = agent.train_model(model=model_ddpg, \n",
        "                             tb_log_name='ddpg',\n",
        "                             total_timesteps=30000)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to tensorboard_log/ddpg/ddpg_1\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 1e+05    |\n",
            "|    total_cost       | 0        |\n",
            "|    total_reward     | 0        |\n",
            "|    total_reward_pct | 0        |\n",
            "|    total_trades     | 0        |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 135      |\n",
            "|    time_elapsed     | 74       |\n",
            "|    total timesteps  | 10064    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 2.32e+03 |\n",
            "|    critic_loss      | 4.86e+03 |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    n_updates        | 7548     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 1e+05    |\n",
            "|    total_cost       | 0        |\n",
            "|    total_reward     | 0        |\n",
            "|    total_reward_pct | 0        |\n",
            "|    total_trades     | 0        |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 120      |\n",
            "|    time_elapsed     | 167      |\n",
            "|    total timesteps  | 20128    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 1.37e+03 |\n",
            "|    critic_loss      | 2.91e+03 |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    n_updates        | 17612    |\n",
            "----------------------------------\n",
            "day: 2515, episode: 30\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 100000.00\n",
            "total_reward: 0.00\n",
            "total_cost: 0.00\n",
            "total_trades: 0\n",
            "=================================\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 1e+05    |\n",
            "|    total_cost       | 0        |\n",
            "|    total_reward     | 0        |\n",
            "|    total_reward_pct | 0        |\n",
            "|    total_trades     | 0        |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 115      |\n",
            "|    time_elapsed     | 260      |\n",
            "|    total timesteps  | 30192    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 804      |\n",
            "|    critic_loss      | 1.74e+03 |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    n_updates        | 27676    |\n",
            "----------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sve9WGvsC__"
      },
      "source": [
        "### Model 3: PPO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOjuycpS-Qvn",
        "outputId": "7d18da79-cad2-4e76-e3c0-96c8e7d246c8"
      },
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "PPO_PARAMS = {\n",
        "    \"n_steps\": 2048,\n",
        "    \"ent_coef\": 0.005,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"batch_size\": 128,\n",
        "}\n",
        "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.0001, 'batch_size': 128}\n",
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9hCHA8A-RSy",
        "outputId": "f8822e8b-c99f-44dc-d192-c1a2c47e6b0e"
      },
      "source": [
        "trained_ppo = agent.train_model(model=model_ppo, \n",
        "                             tb_log_name='ppo',\n",
        "                             total_timesteps=80000)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to tensorboard_log/ppo/ppo_1\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 522  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 3    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 1.63e+05     |\n",
            "|    total_cost           | 3.25e+03     |\n",
            "|    total_reward         | 6.26e+04     |\n",
            "|    total_reward_pct     | 62.6         |\n",
            "|    total_trades         | 2501         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 471          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 8            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023498312 |\n",
            "|    clip_fraction        | 0.000342     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | -1.64e+12    |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.0101       |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.000463    |\n",
            "|    std                  | 0.997        |\n",
            "|    value_loss           | 0.024        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 1.01e+05    |\n",
            "|    total_cost           | 2.65e+03    |\n",
            "|    total_reward         | 880         |\n",
            "|    total_reward_pct     | 0.88        |\n",
            "|    total_trades         | 2360        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 450         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 13          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008674588 |\n",
            "|    clip_fraction        | 0.0195      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | -5.3e+12    |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 0.00425     |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.000956   |\n",
            "|    std                  | 0.997       |\n",
            "|    value_loss           | 0.0192      |\n",
            "-----------------------------------------\n",
            "--------------------------------------------\n",
            "| environment/            |                |\n",
            "|    portfolio_value      | 9.85e+04       |\n",
            "|    total_cost           | 2.81e+03       |\n",
            "|    total_reward         | -1.5e+03       |\n",
            "|    total_reward_pct     | -1.5           |\n",
            "|    total_trades         | 2355           |\n",
            "| time/                   |                |\n",
            "|    fps                  | 438            |\n",
            "|    iterations           | 4              |\n",
            "|    time_elapsed         | 18             |\n",
            "|    total_timesteps      | 8192           |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | -0.00015832146 |\n",
            "|    clip_fraction        | 0.0084         |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.42          |\n",
            "|    explained_variance   | -1.48e+11      |\n",
            "|    learning_rate        | 0.0001         |\n",
            "|    loss                 | -0.00824       |\n",
            "|    n_updates            | 30             |\n",
            "|    policy_gradient_loss | -0.00119       |\n",
            "|    std                  | 0.999          |\n",
            "|    value_loss           | 0.0014         |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 1.09e+05     |\n",
            "|    total_cost           | 2.9e+03      |\n",
            "|    total_reward         | 8.79e+03     |\n",
            "|    total_reward_pct     | 8.79         |\n",
            "|    total_trades         | 2418         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 440          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005431544 |\n",
            "|    clip_fraction        | 9.77e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | nan          |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | -0.0059      |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | 4.25e-05     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.00347      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 437          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 28           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019681582 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | nan          |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | -0.0155      |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.000197    |\n",
            "|    std                  | 0.996        |\n",
            "|    value_loss           | 0.0109       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 1.1e+05     |\n",
            "|    total_cost           | 2.63e+03    |\n",
            "|    total_reward         | 9.9e+03     |\n",
            "|    total_reward_pct     | 9.9         |\n",
            "|    total_trades         | 2364        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 435         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 32          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005276547 |\n",
            "|    clip_fraction        | 0.00513     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | -6.75e+12   |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 0.00338     |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.000453   |\n",
            "|    std                  | 0.996       |\n",
            "|    value_loss           | 0.00616     |\n",
            "-----------------------------------------\n",
            "day: 2515, episode: 40\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 102639.65\n",
            "total_reward: 2639.65\n",
            "total_cost: 2645.05\n",
            "total_trades: 2262\n",
            "Sharpe: 0.106\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 1.03e+05    |\n",
            "|    total_cost           | 2.65e+03    |\n",
            "|    total_reward         | 2.64e+03    |\n",
            "|    total_reward_pct     | 2.64        |\n",
            "|    total_trades         | 2262        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 37          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005755849 |\n",
            "|    clip_fraction        | 0.0158      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | -1.71e+12   |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | -0.00672    |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0012     |\n",
            "|    std                  | 0.993       |\n",
            "|    value_loss           | 0.000426    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 1.09e+05    |\n",
            "|    total_cost           | 3.15e+03    |\n",
            "|    total_reward         | 9.48e+03    |\n",
            "|    total_reward_pct     | 9.48        |\n",
            "|    total_trades         | 2425        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 432         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 42          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004733339 |\n",
            "|    clip_fraction        | 0.0122      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | nan         |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | -0.0223     |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00132    |\n",
            "|    std                  | 0.99        |\n",
            "|    value_loss           | 0.00403     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 2.43e+05     |\n",
            "|    total_cost           | 3.18e+03     |\n",
            "|    total_reward         | 1.43e+05     |\n",
            "|    total_reward_pct     | 143          |\n",
            "|    total_trades         | 2515         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 47           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025113744 |\n",
            "|    clip_fraction        | 0.0167       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | -43.8        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.00872      |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00127     |\n",
            "|    std                  | 0.99         |\n",
            "|    value_loss           | 0.0528       |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 430            |\n",
            "|    iterations           | 11             |\n",
            "|    time_elapsed         | 52             |\n",
            "|    total_timesteps      | 22528          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | -8.3515915e-05 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.41          |\n",
            "|    explained_variance   | -8.22          |\n",
            "|    learning_rate        | 0.0001         |\n",
            "|    loss                 | 0.246          |\n",
            "|    n_updates            | 100            |\n",
            "|    policy_gradient_loss | -0.000265      |\n",
            "|    std                  | 0.992          |\n",
            "|    value_loss           | 0.574          |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 3.01e+05      |\n",
            "|    total_cost           | 3.15e+03      |\n",
            "|    total_reward         | 2.01e+05      |\n",
            "|    total_reward_pct     | 201           |\n",
            "|    total_trades         | 2510          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 430           |\n",
            "|    iterations           | 12            |\n",
            "|    time_elapsed         | 57            |\n",
            "|    total_timesteps      | 24576         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00011495419 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.41         |\n",
            "|    explained_variance   | -14.3         |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 0.156         |\n",
            "|    n_updates            | 110           |\n",
            "|    policy_gradient_loss | -5.93e-05     |\n",
            "|    std                  | 0.993         |\n",
            "|    value_loss           | 0.445         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 2.46e+05     |\n",
            "|    total_cost           | 3.28e+03     |\n",
            "|    total_reward         | 1.46e+05     |\n",
            "|    total_reward_pct     | 146          |\n",
            "|    total_trades         | 2506         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 428          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 62           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036293664 |\n",
            "|    clip_fraction        | 0.00928      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | -18.8        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.262        |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00128     |\n",
            "|    std                  | 0.994        |\n",
            "|    value_loss           | 0.506        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 1.52e+05      |\n",
            "|    total_cost           | 3.31e+03      |\n",
            "|    total_reward         | 5.19e+04      |\n",
            "|    total_reward_pct     | 51.9          |\n",
            "|    total_trades         | 2508          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 428           |\n",
            "|    iterations           | 14            |\n",
            "|    time_elapsed         | 66            |\n",
            "|    total_timesteps      | 28672         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00030583248 |\n",
            "|    clip_fraction        | 4.88e-05      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | -10.7         |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 0.271         |\n",
            "|    n_updates            | 130           |\n",
            "|    policy_gradient_loss | -0.000758     |\n",
            "|    std                  | 0.999         |\n",
            "|    value_loss           | 0.397         |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| environment/            |                |\n",
            "|    portfolio_value      | 2.53e+05       |\n",
            "|    total_cost           | 3.39e+03       |\n",
            "|    total_reward         | 1.53e+05       |\n",
            "|    total_reward_pct     | 153            |\n",
            "|    total_trades         | 2515           |\n",
            "| time/                   |                |\n",
            "|    fps                  | 428            |\n",
            "|    iterations           | 15             |\n",
            "|    time_elapsed         | 71             |\n",
            "|    total_timesteps      | 30720          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | -5.9177517e-05 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.42          |\n",
            "|    explained_variance   | -8.3           |\n",
            "|    learning_rate        | 0.0001         |\n",
            "|    loss                 | 0.0777         |\n",
            "|    n_updates            | 140            |\n",
            "|    policy_gradient_loss | -0.000142      |\n",
            "|    std                  | 0.999          |\n",
            "|    value_loss           | 0.181          |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 2.34e+05     |\n",
            "|    total_cost           | 3.29e+03     |\n",
            "|    total_reward         | 1.34e+05     |\n",
            "|    total_reward_pct     | 134          |\n",
            "|    total_trades         | 2513         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 428          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 76           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012902236 |\n",
            "|    clip_fraction        | 0.00229      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | -15.4        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.285        |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.000179    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.454        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 427           |\n",
            "|    iterations           | 17            |\n",
            "|    time_elapsed         | 81            |\n",
            "|    total_timesteps      | 34816         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00082203746 |\n",
            "|    clip_fraction        | 0.00454       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | -9.08         |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 0.12          |\n",
            "|    n_updates            | 160           |\n",
            "|    policy_gradient_loss | -0.000547     |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 0.33          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 2.02e+05     |\n",
            "|    total_cost           | 3.36e+03     |\n",
            "|    total_reward         | 1.02e+05     |\n",
            "|    total_reward_pct     | 102          |\n",
            "|    total_trades         | 2513         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 86           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012473622 |\n",
            "|    clip_fraction        | 0.0178       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | -2.63        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.0284       |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.000701    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.0856       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 2.75e+05     |\n",
            "|    total_cost           | 3.34e+03     |\n",
            "|    total_reward         | 1.75e+05     |\n",
            "|    total_reward_pct     | 175          |\n",
            "|    total_trades         | 2509         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 91           |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014541507 |\n",
            "|    clip_fraction        | 0.0022       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | -5.55        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.109        |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.000536    |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.32         |\n",
            "------------------------------------------\n",
            "day: 2515, episode: 50\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 245243.73\n",
            "total_reward: 145243.73\n",
            "total_cost: 3379.21\n",
            "total_trades: 2513\n",
            "Sharpe: 0.656\n",
            "=================================\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 2.45e+05     |\n",
            "|    total_cost           | 3.38e+03     |\n",
            "|    total_reward         | 1.45e+05     |\n",
            "|    total_reward_pct     | 145          |\n",
            "|    total_trades         | 2513         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 96           |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036485041 |\n",
            "|    clip_fraction        | 0.00122      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | -27.7        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.435        |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00108     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.617        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 2.69e+05    |\n",
            "|    total_cost           | 3.39e+03    |\n",
            "|    total_reward         | 1.69e+05    |\n",
            "|    total_reward_pct     | 169         |\n",
            "|    total_trades         | 2515        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 101         |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004209143 |\n",
            "|    clip_fraction        | 0.00415     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | -34         |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 0.126       |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.00122    |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.345       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 106         |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003858869 |\n",
            "|    clip_fraction        | 0.00825     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.43       |\n",
            "|    explained_variance   | -17.2       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 0.306       |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.00104    |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.628       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 3.65e+05     |\n",
            "|    total_cost           | 3.41e+03     |\n",
            "|    total_reward         | 2.65e+05     |\n",
            "|    total_reward_pct     | 265          |\n",
            "|    total_trades         | 2514         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 111          |\n",
            "|    total_timesteps      | 47104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009270533 |\n",
            "|    clip_fraction        | 0.00107      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.43        |\n",
            "|    explained_variance   | -34.5        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.287        |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00105     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.565        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 4.31e+05     |\n",
            "|    total_cost           | 3.22e+03     |\n",
            "|    total_reward         | 3.31e+05     |\n",
            "|    total_reward_pct     | 331          |\n",
            "|    total_trades         | 2515         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 115          |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059802216 |\n",
            "|    clip_fraction        | 0.0267       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | -11.3        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.467        |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.00326     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.03         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 5.7e+05       |\n",
            "|    total_cost           | 2.97e+03      |\n",
            "|    total_reward         | 4.7e+05       |\n",
            "|    total_reward_pct     | 470           |\n",
            "|    total_trades         | 2513          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 424           |\n",
            "|    iterations           | 25            |\n",
            "|    time_elapsed         | 120           |\n",
            "|    total_timesteps      | 51200         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.7798215e-05 |\n",
            "|    clip_fraction        | 0.000635      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | -5.18         |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 1.1           |\n",
            "|    n_updates            | 240           |\n",
            "|    policy_gradient_loss | -0.000605     |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 1.95          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 4.61e+05     |\n",
            "|    total_cost           | 2.94e+03     |\n",
            "|    total_reward         | 3.61e+05     |\n",
            "|    total_reward_pct     | 361          |\n",
            "|    total_trades         | 2515         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 125          |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013475157 |\n",
            "|    clip_fraction        | 0.00361      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | -5.27        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 1.43         |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.000743    |\n",
            "|    std                  | 0.999        |\n",
            "|    value_loss           | 3.39         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 27           |\n",
            "|    time_elapsed         | 130          |\n",
            "|    total_timesteps      | 55296        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016716851 |\n",
            "|    clip_fraction        | 0.00132      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | -4.19        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 1.95         |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.000868    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.45         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 4.27e+05      |\n",
            "|    total_cost           | 3.04e+03      |\n",
            "|    total_reward         | 3.27e+05      |\n",
            "|    total_reward_pct     | 327           |\n",
            "|    total_trades         | 2515          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 424           |\n",
            "|    iterations           | 28            |\n",
            "|    time_elapsed         | 135           |\n",
            "|    total_timesteps      | 57344         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00081697694 |\n",
            "|    clip_fraction        | 0.000195      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | -6.26         |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 0.539         |\n",
            "|    n_updates            | 270           |\n",
            "|    policy_gradient_loss | -0.000526     |\n",
            "|    std                  | 0.998         |\n",
            "|    value_loss           | 1.3           |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 3.93e+05      |\n",
            "|    total_cost           | 3.26e+03      |\n",
            "|    total_reward         | 2.93e+05      |\n",
            "|    total_reward_pct     | 293           |\n",
            "|    total_trades         | 2515          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 424           |\n",
            "|    iterations           | 29            |\n",
            "|    time_elapsed         | 139           |\n",
            "|    total_timesteps      | 59392         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00060773623 |\n",
            "|    clip_fraction        | 0.00117       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | -3.23         |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 0.672         |\n",
            "|    n_updates            | 280           |\n",
            "|    policy_gradient_loss | -0.000921     |\n",
            "|    std                  | 0.998         |\n",
            "|    value_loss           | 1.26          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| environment/            |             |\n",
            "|    portfolio_value      | 3.81e+05    |\n",
            "|    total_cost           | 3.29e+03    |\n",
            "|    total_reward         | 2.81e+05    |\n",
            "|    total_reward_pct     | 281         |\n",
            "|    total_trades         | 2514        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 144         |\n",
            "|    total_timesteps      | 61440       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004097117 |\n",
            "|    clip_fraction        | 0.0334      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | -11.9       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 0.622       |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.00333    |\n",
            "|    std                  | 0.996       |\n",
            "|    value_loss           | 1.23        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 3.82e+05     |\n",
            "|    total_cost           | 3.19e+03     |\n",
            "|    total_reward         | 2.82e+05     |\n",
            "|    total_reward_pct     | 282          |\n",
            "|    total_trades         | 2513         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 149          |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036761742 |\n",
            "|    clip_fraction        | 0.0343       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | -16.8        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.408        |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00408     |\n",
            "|    std                  | 0.992        |\n",
            "|    value_loss           | 1.16         |\n",
            "------------------------------------------\n",
            "day: 2515, episode: 60\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 407194.99\n",
            "total_reward: 307194.99\n",
            "total_cost: 3281.87\n",
            "total_trades: 2515\n",
            "Sharpe: 0.817\n",
            "=================================\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 4.07e+05     |\n",
            "|    total_cost           | 3.28e+03     |\n",
            "|    total_reward         | 3.07e+05     |\n",
            "|    total_reward_pct     | 307          |\n",
            "|    total_trades         | 2515         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 154          |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031483532 |\n",
            "|    clip_fraction        | 0.00684      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | -5.17        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.818        |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.00152     |\n",
            "|    std                  | 0.994        |\n",
            "|    value_loss           | 1.52         |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 424            |\n",
            "|    iterations           | 33             |\n",
            "|    time_elapsed         | 159            |\n",
            "|    total_timesteps      | 67584          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | -2.6143389e-06 |\n",
            "|    clip_fraction        | 0.000635       |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.41          |\n",
            "|    explained_variance   | -14.6          |\n",
            "|    learning_rate        | 0.0001         |\n",
            "|    loss                 | 0.832          |\n",
            "|    n_updates            | 320            |\n",
            "|    policy_gradient_loss | -0.000956      |\n",
            "|    std                  | 0.992          |\n",
            "|    value_loss           | 1.62           |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 4.08e+05      |\n",
            "|    total_cost           | 3.28e+03      |\n",
            "|    total_reward         | 3.08e+05      |\n",
            "|    total_reward_pct     | 308           |\n",
            "|    total_trades         | 2515          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 424           |\n",
            "|    iterations           | 34            |\n",
            "|    time_elapsed         | 163           |\n",
            "|    total_timesteps      | 69632         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 3.9090635e-05 |\n",
            "|    clip_fraction        | 0.000146      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.41         |\n",
            "|    explained_variance   | -3.31         |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 0.462         |\n",
            "|    n_updates            | 330           |\n",
            "|    policy_gradient_loss | -0.00051      |\n",
            "|    std                  | 0.992         |\n",
            "|    value_loss           | 0.832         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 4.14e+05     |\n",
            "|    total_cost           | 3.39e+03     |\n",
            "|    total_reward         | 3.14e+05     |\n",
            "|    total_reward_pct     | 314          |\n",
            "|    total_trades         | 2515         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 168          |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004524811 |\n",
            "|    clip_fraction        | 0.00195      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | -6.01        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.928        |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.00179     |\n",
            "|    std                  | 0.987        |\n",
            "|    value_loss           | 1.48         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 3.81e+05     |\n",
            "|    total_cost           | 3.34e+03     |\n",
            "|    total_reward         | 2.81e+05     |\n",
            "|    total_reward_pct     | 281          |\n",
            "|    total_trades         | 2510         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 173          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018058646 |\n",
            "|    clip_fraction        | 0.0062       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | -7.22        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.687        |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.000674    |\n",
            "|    std                  | 0.986        |\n",
            "|    value_loss           | 1.58         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 4.18e+05     |\n",
            "|    total_cost           | 3.37e+03     |\n",
            "|    total_reward         | 3.18e+05     |\n",
            "|    total_reward_pct     | 318          |\n",
            "|    total_trades         | 2514         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 178          |\n",
            "|    total_timesteps      | 75776        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047114547 |\n",
            "|    clip_fraction        | 0.0042       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | -8.62        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.599        |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.00111     |\n",
            "|    std                  | 0.988        |\n",
            "|    value_loss           | 1.32         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 183          |\n",
            "|    total_timesteps      | 77824        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030143163 |\n",
            "|    clip_fraction        | 0.0118       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | -19.5        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.868        |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.00132     |\n",
            "|    std                  | 0.991        |\n",
            "|    value_loss           | 1.69         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| environment/            |              |\n",
            "|    portfolio_value      | 5.35e+05     |\n",
            "|    total_cost           | 3.23e+03     |\n",
            "|    total_reward         | 4.35e+05     |\n",
            "|    total_reward_pct     | 435          |\n",
            "|    total_trades         | 2514         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 187          |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038764367 |\n",
            "|    clip_fraction        | 0.00483      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | -28.4        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 0.832        |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.00148     |\n",
            "|    std                  | 0.989        |\n",
            "|    value_loss           | 1.61         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| environment/            |               |\n",
            "|    portfolio_value      | 6.24e+05      |\n",
            "|    total_cost           | 3.11e+03      |\n",
            "|    total_reward         | 5.24e+05      |\n",
            "|    total_reward_pct     | 524           |\n",
            "|    total_trades         | 2514          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 425           |\n",
            "|    iterations           | 40            |\n",
            "|    time_elapsed         | 192           |\n",
            "|    total_timesteps      | 81920         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | -0.0009940406 |\n",
            "|    clip_fraction        | 0.000293      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.41         |\n",
            "|    explained_variance   | -13.5         |\n",
            "|    learning_rate        | 0.0001        |\n",
            "|    loss                 | 1.49          |\n",
            "|    n_updates            | 390           |\n",
            "|    policy_gradient_loss | -0.000401     |\n",
            "|    std                  | 0.988         |\n",
            "|    value_loss           | 3.1           |\n",
            "-------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiBG2ZknsG73"
      },
      "source": [
        "### Model 4: TD3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcRdoBc8-Xze",
        "outputId": "2d958cad-7f2b-475a-fad7-d2e1b4a17c6d"
      },
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "TD3_PARAMS = {\"batch_size\": 128, \n",
        "              \"buffer_size\": 1000000, \n",
        "              \"learning_rate\": 0.0003}\n",
        "\n",
        "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0003}\n",
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB5cAAio-ZSs",
        "outputId": "cfc37780-f785-4646-8c8f-8be67df61e41"
      },
      "source": [
        "trained_td3 = agent.train_model(model=model_td3, \n",
        "                             tb_log_name='td3',\n",
        "                             total_timesteps=30000)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to tensorboard_log/td3/td3_1\n",
            "day: 2515, episode: 70\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 100000.00\n",
            "total_reward: 0.00\n",
            "total_cost: 0.00\n",
            "total_trades: 0\n",
            "=================================\n",
            "-----------------------------------\n",
            "| environment/        |           |\n",
            "|    portfolio_value  | 1e+05     |\n",
            "|    total_cost       | 0         |\n",
            "|    total_reward     | 0         |\n",
            "|    total_reward_pct | 0         |\n",
            "|    total_trades     | 0         |\n",
            "| time/               |           |\n",
            "|    episodes         | 4         |\n",
            "|    fps              | 143       |\n",
            "|    time_elapsed     | 69        |\n",
            "|    total timesteps  | 10064     |\n",
            "| train/              |           |\n",
            "|    actor_loss       | -3.44e+03 |\n",
            "|    critic_loss      | 2.56e+04  |\n",
            "|    learning_rate    | 0.0003    |\n",
            "|    n_updates        | 7548      |\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "| environment/        |           |\n",
            "|    portfolio_value  | 1e+05     |\n",
            "|    total_cost       | 0         |\n",
            "|    total_reward     | 0         |\n",
            "|    total_reward_pct | 0         |\n",
            "|    total_trades     | 0         |\n",
            "| time/               |           |\n",
            "|    episodes         | 8         |\n",
            "|    fps              | 127       |\n",
            "|    time_elapsed     | 158       |\n",
            "|    total timesteps  | 20128     |\n",
            "| train/              |           |\n",
            "|    actor_loss       | -2.65e+03 |\n",
            "|    critic_loss      | 1.03e+04  |\n",
            "|    learning_rate    | 0.0003    |\n",
            "|    n_updates        | 17612     |\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "| environment/        |           |\n",
            "|    portfolio_value  | 1e+05     |\n",
            "|    total_cost       | 0         |\n",
            "|    total_reward     | 0         |\n",
            "|    total_reward_pct | 0         |\n",
            "|    total_trades     | 0         |\n",
            "| time/               |           |\n",
            "|    episodes         | 12        |\n",
            "|    fps              | 122       |\n",
            "|    time_elapsed     | 247       |\n",
            "|    total timesteps  | 30192     |\n",
            "| train/              |           |\n",
            "|    actor_loss       | -2.04e+03 |\n",
            "|    critic_loss      | 4.12e+03  |\n",
            "|    learning_rate    | 0.0003    |\n",
            "|    n_updates        | 27676     |\n",
            "-----------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDk2qrlTLZCp"
      },
      "source": [
        "### Model 4: SAC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el8sK4fo-dl1",
        "outputId": "cab124f3-8a96-4faf-b900-3b658ec3ce8d"
      },
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "SAC_PARAMS = {\n",
        "    \"batch_size\": 128,\n",
        "    \"buffer_size\": 100000,\n",
        "    \"learning_rate\": 0.00003,\n",
        "    \"learning_starts\": 100,\n",
        "    \"ent_coef\": \"auto_0.1\",\n",
        "}\n",
        "\n",
        "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 3e-05, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaF80PR0-d_d",
        "outputId": "902fa677-1c91-4fae-e9b6-905ee7ef99c7"
      },
      "source": [
        "trained_sac = agent.train_model(model=model_sac, \n",
        "                             tb_log_name='sac',\n",
        "                             total_timesteps=30000)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to tensorboard_log/sac/sac_1\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 1e+05    |\n",
            "|    total_cost       | 0        |\n",
            "|    total_reward     | 0        |\n",
            "|    total_reward_pct | 0        |\n",
            "|    total_trades     | 0        |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 69       |\n",
            "|    time_elapsed     | 144      |\n",
            "|    total timesteps  | 10064    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 2.2e+03  |\n",
            "|    critic_loss      | 361      |\n",
            "|    ent_coef         | 0.135    |\n",
            "|    ent_coef_loss    | 63.9     |\n",
            "|    learning_rate    | 3e-05    |\n",
            "|    n_updates        | 9963     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| environment/        |          |\n",
            "|    portfolio_value  | 1e+05    |\n",
            "|    total_cost       | 0        |\n",
            "|    total_reward     | 0        |\n",
            "|    total_reward_pct | 0        |\n",
            "|    total_trades     | 0        |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 69       |\n",
            "|    time_elapsed     | 290      |\n",
            "|    total timesteps  | 20128    |\n",
            "| train/              |          |\n",
            "|    actor_loss       | 1.54e+03 |\n",
            "|    critic_loss      | 401      |\n",
            "|    ent_coef         | 0.183    |\n",
            "|    ent_coef_loss    | 54.3     |\n",
            "|    learning_rate    | 3e-05    |\n",
            "|    n_updates        | 20027    |\n",
            "----------------------------------\n",
            "day: 2515, episode: 90\n",
            "begin_total_asset: 100000.00\n",
            "end_total_asset: 100000.00\n",
            "total_reward: 0.00\n",
            "total_cost: 0.00\n",
            "total_trades: 0\n",
            "=================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE1Xm9N9TnTn"
      },
      "source": [
        "### Trading\n",
        "* we use the environment class we initialized at 5.3 to create a stock trading environment\n",
        "* Assume that we have $100,000 initial capital at 2019-01-01. \n",
        "* We use the trained model of PPO to trade AAPL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "kLFUwxhCoHN_",
        "outputId": "e9b70394-74f3-4974-ab48-a422bc279a5e"
      },
      "source": [
        "trade.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>kdjk</th>\n",
              "      <th>open_2_sma</th>\n",
              "      <th>boll</th>\n",
              "      <th>close_10.0_le_5_c</th>\n",
              "      <th>wr_10</th>\n",
              "      <th>dma</th>\n",
              "      <th>trix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>38.722500</td>\n",
              "      <td>39.712502</td>\n",
              "      <td>38.557499</td>\n",
              "      <td>38.562561</td>\n",
              "      <td>148158800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.019903</td>\n",
              "      <td>37.867349</td>\n",
              "      <td>-91.567852</td>\n",
              "      <td>42.250808</td>\n",
              "      <td>27.327775</td>\n",
              "      <td>39.177500</td>\n",
              "      <td>40.034790</td>\n",
              "      <td>0.0</td>\n",
              "      <td>63.418114</td>\n",
              "      <td>-6.886014</td>\n",
              "      <td>-0.761652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-01-03</td>\n",
              "      <td>35.994999</td>\n",
              "      <td>36.430000</td>\n",
              "      <td>35.500000</td>\n",
              "      <td>34.721451</td>\n",
              "      <td>365248800</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>3</td>\n",
              "      <td>-2.203028</td>\n",
              "      <td>32.751919</td>\n",
              "      <td>-177.961195</td>\n",
              "      <td>55.246973</td>\n",
              "      <td>13.056580</td>\n",
              "      <td>37.358749</td>\n",
              "      <td>39.514298</td>\n",
              "      <td>0.0</td>\n",
              "      <td>112.236531</td>\n",
              "      <td>-7.096225</td>\n",
              "      <td>-0.763466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-01-04</td>\n",
              "      <td>36.132500</td>\n",
              "      <td>37.137501</td>\n",
              "      <td>35.950001</td>\n",
              "      <td>36.203678</td>\n",
              "      <td>234428400</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>4</td>\n",
              "      <td>-2.203157</td>\n",
              "      <td>36.192789</td>\n",
              "      <td>-139.712389</td>\n",
              "      <td>47.060632</td>\n",
              "      <td>14.108980</td>\n",
              "      <td>36.063749</td>\n",
              "      <td>39.167181</td>\n",
              "      <td>0.0</td>\n",
              "      <td>86.003419</td>\n",
              "      <td>-7.054847</td>\n",
              "      <td>-0.766086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-01-07</td>\n",
              "      <td>37.174999</td>\n",
              "      <td>37.207500</td>\n",
              "      <td>36.474998</td>\n",
              "      <td>36.123104</td>\n",
              "      <td>219111200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.184578</td>\n",
              "      <td>36.088949</td>\n",
              "      <td>-122.741121</td>\n",
              "      <td>46.245025</td>\n",
              "      <td>14.191732</td>\n",
              "      <td>36.653749</td>\n",
              "      <td>38.840088</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.642763</td>\n",
              "      <td>-6.910649</td>\n",
              "      <td>-0.767321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-08</td>\n",
              "      <td>37.389999</td>\n",
              "      <td>37.955002</td>\n",
              "      <td>37.130001</td>\n",
              "      <td>36.811718</td>\n",
              "      <td>164101200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>1</td>\n",
              "      <td>-2.090194</td>\n",
              "      <td>37.669998</td>\n",
              "      <td>-95.012445</td>\n",
              "      <td>37.537680</td>\n",
              "      <td>19.535793</td>\n",
              "      <td>37.282499</td>\n",
              "      <td>38.623490</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.776084</td>\n",
              "      <td>-6.599589</td>\n",
              "      <td>-0.759067</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date       open       high  ...       wr_10       dma      trix\n",
              "0  2019-01-02  38.722500  39.712502  ...   63.418114 -6.886014 -0.761652\n",
              "1  2019-01-03  35.994999  36.430000  ...  112.236531 -7.096225 -0.763466\n",
              "2  2019-01-04  36.132500  37.137501  ...   86.003419 -7.054847 -0.766086\n",
              "3  2019-01-07  37.174999  37.207500  ...   85.642763 -6.910649 -0.767321\n",
              "4  2019-01-08  37.389999  37.955002  ...   69.776084 -6.599589 -0.759067\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLHl6V7eqV6_"
      },
      "source": [
        "## make a prediction and get the account value change\n",
        "trade = data_split(data_df, start = '2019-01-01', end = '2021-01-01')\n",
        "\n",
        "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
        "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
        "\n",
        "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_sac,\n",
        "                                           test_data = trade,\n",
        "                                           test_env = env_trade,\n",
        "                                           test_obs = obs_trade)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYXxFzD5TnTw"
      },
      "source": [
        "<a id='6'></a>\n",
        "# Part 7: Backtesting Performance\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GwqOO-v1NVz"
      },
      "source": [
        "<a id='6.1'></a>\n",
        "## 7.1 BackTestStats\n",
        "pass in df_account_value, this information is stored in env class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "C9cpPm9YYxHC",
        "outputId": "74d89cd8-5184-4d7c-f717-a6516f8f7d02"
      },
      "source": [
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = BackTestStats(account_value=df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
        "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============Get Backtest Results===========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-24958daad3f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%d-%Hh%M'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mperf_stats_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackTestStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_account_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mperf_stats_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf_stats_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mperf_stats_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESULTS_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/perf_stats_all_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/finrl/trade/backtest.py\u001b[0m in \u001b[0;36mBackTestStats\u001b[0;34m(account_value)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mBackTestStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccount_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_daily_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mDRL_strat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbacktest_strat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mperf_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/finrl/trade/backtest.py\u001b[0m in \u001b[0;36mget_daily_return\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"daily_return\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccount_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpct_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# df=df.dropna()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0msharpe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m252\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"daily_return\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"daily_return\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mannual_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"daily_return\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m252\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-Tenjb0hcNr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4Gw3HNr1TDU"
      },
      "source": [
        "<a id='6.2'></a>\n",
        "## 7.2 BackTestPlot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA_8LuZE1J3X"
      },
      "source": [
        "print(\"==============Compare to AAPL itself buy-and-hold===========\")\n",
        "%matplotlib inline\n",
        "BackTestPlot(account_value=df_account_value, \n",
        "             baseline_ticker = 'AAPL',\n",
        "             baseline_start = '2019-01-01',\n",
        "             baseline_end = '2021-01-01')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSFMdgCJE4O-"
      },
      "source": [
        "<a id='6.3'></a>\n",
        "## 7.3 Baseline Stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpR7aQIwqdC4"
      },
      "source": [
        "print(\"==============Get Baseline Stats===========\")\n",
        "baesline_perf_stats=BaselineStats('AAPL')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSFRXQfYFTQf"
      },
      "source": [
        "print(\"==============Get Baseline Stats===========\")\n",
        "baesline_perf_stats=BaselineStats('^GSPC')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tunrA4mjE9la"
      },
      "source": [
        "<a id='6.4'></a>\n",
        "## 7.4 Compare to Stock Market Index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ca2gHxi1gzX"
      },
      "source": [
        "print(\"==============Compare to S&P 500===========\")\n",
        "%matplotlib inline\n",
        "# S&P 500: ^GSPC\n",
        "# Dow Jones Index: ^DJI\n",
        "# NASDAQ 100: ^NDX\n",
        "BackTestPlot(df_account_value, baseline_ticker = '^GSPC')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_aHGEOTCluG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}